return(predicted_emoji)
} else if (output_type == "textemoji") {
# 返回带 emoji 的文本并打印
result_text <- paste0(text, " ", predicted_emoji)
cat(result_text, "\n")
return(result_text)
} else {
stop("Invalid output_type. Please choose 'emotion', 'emoji', or 'textemoji'.")
}
}
# 示例：用户输入
user_input <- "I am happy!"
# 只返回情绪标签
result_emotion <- predict_emotion_with_emoji(user_input, "emotion")
# 只返回对应的 emoji
result_emoji <- predict_emotion_with_emoji(user_input, "emoji")
# 返回带有 emoji 的完整文本（默认参数）
result_textemoji <- predict_emotion_with_emoji(user_input)  # 默认参数是 "textemoji"
#' Preprocess Text with Slang Handling
#'
#' This function performs multi-stage text preprocessing, including lowercasing,
#' HTML cleaning, punctuation normalization, contraction expansion, internet slang replacement,
#' emoticon replacement, and final standardization.
#'
#' @param text A character vector of input texts.
#' @param use_textclean Logical. Whether to use \code{textclean} for internet slang and emoticon replacement. Default is \code{TRUE}.
#' @param custom_slang A named character vector providing user-defined slang mappings. Optional.
#'
#' @return  A character vector of cleaned and normalized text.
#'
#' @details
#' The preprocessing pipeline includes:
#' \itemize{
#'   \item Lowercasing the text.
#'   \item Replacing HTML entities and non-ASCII characters.
#'   \item Expanding common English contractions (e.g., "I'm" -> "I am").
#'   \item Replacing internet slang and emoticons if \code{use_textclean} is \code{TRUE}.
#'   \item Handling additional slang defined by the user.
#'   \item Normalizing repeated punctuations and whitespace.
#' }
#'
#' @examples
#' preprocess_text("I'm feeling lit rn!!!")
#' preprocess_text("I can't believe it... lol :)", use_textclean = TRUE)
#'
#' @importFrom stringr str_to_lower str_replace_all str_squish
#' @importFrom textclean replace_html replace_non_ascii replace_internet_slang replace_emoticon
#' @importFrom magrittr %>%
#' @export
preprocess_text <- function(text,
use_textclean = TRUE,
custom_slang = NULL) {
# 阶段1：基础清洗
text <- text %>%
stringr::str_to_lower() %>%
# 处理HTML实体（如&nbsp;）
textclean::replace_html() %>%
# 标准化标点（全角转半角等）
textclean::replace_non_ascii()
# 阶段2：收缩词处理
contractions <- c(
# 优先处理带"ll"的
"i'll" = "i will",
"he'll" = "he will",
"she'll" = "she will",
"we'll" = "we will",
"you'll" = "you will",
"they'll" = "they will",
# 然后处理其他
"i'm" = "i am",
"you're" = "you are",
"he's" = "he is",
"she's" = "she is",
"it's" = "it is",
"we're" = "we are",
"they're" = "they are",
"that's" = "that is",
"there's" = "there is",
"here's" = "here is",
"let's" = "let us",
# 最后处理否定形式
"can't" = "can not",
"won't" = "will not",
"don't" = "do not",
"doesn't" = "does not",
"didn't" = "did not",
"isn't" = "is not",
"aren't" = "are not",
"wasn't" = "was not",
"weren't" = "were not",
"haven't" = "have not",
"hasn't" = "has not",
"hadn't" = "had not",
"shan't" = "shall not"
)
text <- text %>%
stringr::str_replace_all(contractions)
# 阶段3：俚语处理
if (use_textclean) {
text <- text %>%
textclean::replace_internet_slang() %>%  # 处理2000+常见网络用语
textclean::replace_emoticon()           # 表情符号转文字
}
all_slang <- c(
"lit" = "extremely amazing",
"af" = "as fuck",
"u" = "you",
"ur" = "your",
"rn" = "right now",
"gg" = "good game",
"gl" = "good luck",
"hf" = "have fun",
"tbh" = "to be honest",
"idc" = "i don't care",
"op" = "overpowered",
"nerf" = "weaken",
"buff" = "strengthen",
"4" = "for",
"2" = "to",
"2nite" = "tonight",
"@" = "at",
"abt" = "about",
"f" = "fuck",
custom_slang
)
for (i in seq_along(all_slang)) {
text <- stringr::str_replace_all(
text,
stringr::regex(
paste0("\\b", names(all_slang)[i], "\\b"),
ignore_case = TRUE
),
all_slang[i]
)
}
# 合并自定义俚语（优先级最高）
if (!is.null(custom_slang)) {
text <- stringr::str_replace_all(
text,
stringr::regex(
paste0("\\b", names(custom_slang), "\\b",
ignore_case = TRUE
),
custom_slang
)
)
}
# 阶段4：最终标准化
text %>%
# 处理重复标点（保留情感强度）
stringr::str_replace_all("([!?.]){2,}", " \\1") %>%
# 保留符号但统一空格
stringr::str_replace_all("([[:punct:]])", " \\1 ") %>%
stringr::str_squish()  # 去除多余空格
}
#' 构建TF-IDF模型（用于训练阶段）
#' @param preprocessed_text 经过预处理的文本向量
#' @param max_features 最大特征数
#' @param min_df 最小文档频率
#' @param max_df 最大文档频率比例
#' @return 包含TF-IDF模型及其组件的列表
#' @export
train_tfidf_model <- function(preprocessed_text,
max_features = 10000,
min_df = 2,
max_df = 0.8,
priority_words = c("happy", "excited", "grateful", "hopeful", "loving",
"annoyed", "furious", "frustrated",
"sad", "lonely", "disappointed", "hopeless",
"scared", "anxious", "nervous",
"factual", "objective", "informative")) {
if (!is.character(preprocessed_text)) {
stop("输入必须是字符向量")
}
# 定义自定义停用词（含保留情感功能词）
custom_stopwords <- c(
"a", "about", "above", "after", "again", "all", "am",
"an", "and", "any", "are", "aren't", "as", "at", "be", "because",
"been", "before", "being", "below", "between", "both", "but", "by",
"can", "can't", "cannot", "could", "couldn't", "did", "didn't", "do",
"does", "doesn't", "doing", "don't", "down", "during", "each", "few",
"for", "from", "further", "had", "hadn't", "has", "hasn't", "have",
"haven't", "having", "he", "he'd", "he'll", "he's", "her", "here",
"hers", "herself", "him", "himself", "his", "how", "i", "i'd", "i'll",
"i'm", "i've", "if", "in", "into", "is", "isn't", "it", "it's", "its",
"itself", "let's", "me", "more", "most", "mustn't", "my", "myself",
"no", "nor", "not", "of", "off", "on", "once", "only", "or", "other",
"ought", "our", "ours", "ourselves", "out", "over", "own", "same",
"she", "she'd", "she'll", "she's", "should", "shouldn't", "so", "some",
"such", "than", "that", "that's", "the", "their", "theirs", "them",
"themselves", "then", "there", "there's", "these", "they", "they'd",
"they'll", "they're", "they've", "this", "those", "through", "to",
"too", "under", "until", "up", "very", "was", "wasn't", "we", "we'd",
"we'll", "we're", "we've", "were", "weren't", "what", "what's",
"when", "when's", "where", "where's", "which", "while", "who", "who's",
"whom", "why", "why's", "will", "with", "won't", "would", "wouldn't",
"you", "you'd", "you'll", "you're", "you've", "your", "yours",
"yourself", "yourselves", "movie", "product","name", "just","people","get",
"one","know","think", "now", "loud", "s","time", "see", "ve", "much", "got",
"go", "way", "tongue" ,"still", "really", "very","d","make", "man", "e", "going",
"back", "thing" , "us", "also", "t", "someone", "say", "something", "day", "look",
"first", "year", "work","looks", "makes", "years", "take", "made", "said",
"life", "post", "things", "find", "getting"
)
# 保留的情感功能词
keep_words <- c("not", "no", "never")
final_stopwords <- setdiff(custom_stopwords, keep_words)
# 分词并移除停用词
tokens <- text2vec::word_tokenizer(tolower(preprocessed_text))
tokens_filtered <- lapply(tokens, function(x) {
x[!x %in% final_stopwords]
})
# 创建itoken迭代器
it <- text2vec::itoken(tokens_filtered, progressbar = FALSE)
# 创建并修剪词汇表（1-3 gram）
vocab <- text2vec::create_vocabulary(it, ngram = c(1L, 3L)) %>%
text2vec::prune_vocabulary(
term_count_min = min_df,
doc_proportion_max = max_df,
vocab_term_max = max_features
)
# 创建向量器和TF-IDF模型
vectorizer <- text2vec::vocab_vectorizer(vocab)
tfidf <- text2vec::TfIdf$new()
# 创建TF-IDF稀疏矩阵
dtm <- text2vec::create_dtm(it, vectorizer)
tfidf_matrix <- tfidf$fit_transform(dtm)
# 返回结果
return(list(
tfidf_model = tfidf,
vectorizer = vectorizer,
tfidf_matrix = tfidf_matrix
))
}
# 示例文本（正面、负面、中性、俚语等）
sample_texts <- readLines(system.file("extdata", "go_emotions_train_text_processed.csv", package = "text2emotion"), warn = FALSE)
trained <- train_tfidf_model(sample_texts)
library(magrittr)
#' 构建TF-IDF模型（用于训练阶段）
#' @param preprocessed_text 经过预处理的文本向量
#' @param max_features 最大特征数
#' @param min_df 最小文档频率
#' @param max_df 最大文档频率比例
#' @return 包含TF-IDF模型及其组件的列表
#' @export
train_tfidf_model <- function(preprocessed_text,
max_features = 10000,
min_df = 2,
max_df = 0.8,
priority_words = c("happy", "excited", "grateful", "hopeful", "loving",
"annoyed", "furious", "frustrated",
"sad", "lonely", "disappointed", "hopeless",
"scared", "anxious", "nervous",
"factual", "objective", "informative")) {
if (!is.character(preprocessed_text)) {
stop("输入必须是字符向量")
}
# 定义自定义停用词（含保留情感功能词）
custom_stopwords <- c(
"a", "about", "above", "after", "again", "all", "am",
"an", "and", "any", "are", "aren't", "as", "at", "be", "because",
"been", "before", "being", "below", "between", "both", "but", "by",
"can", "can't", "cannot", "could", "couldn't", "did", "didn't", "do",
"does", "doesn't", "doing", "don't", "down", "during", "each", "few",
"for", "from", "further", "had", "hadn't", "has", "hasn't", "have",
"haven't", "having", "he", "he'd", "he'll", "he's", "her", "here",
"hers", "herself", "him", "himself", "his", "how", "i", "i'd", "i'll",
"i'm", "i've", "if", "in", "into", "is", "isn't", "it", "it's", "its",
"itself", "let's", "me", "more", "most", "mustn't", "my", "myself",
"no", "nor", "not", "of", "off", "on", "once", "only", "or", "other",
"ought", "our", "ours", "ourselves", "out", "over", "own", "same",
"she", "she'd", "she'll", "she's", "should", "shouldn't", "so", "some",
"such", "than", "that", "that's", "the", "their", "theirs", "them",
"themselves", "then", "there", "there's", "these", "they", "they'd",
"they'll", "they're", "they've", "this", "those", "through", "to",
"too", "under", "until", "up", "very", "was", "wasn't", "we", "we'd",
"we'll", "we're", "we've", "were", "weren't", "what", "what's",
"when", "when's", "where", "where's", "which", "while", "who", "who's",
"whom", "why", "why's", "will", "with", "won't", "would", "wouldn't",
"you", "you'd", "you'll", "you're", "you've", "your", "yours",
"yourself", "yourselves", "movie", "product","name", "just","people","get",
"one","know","think", "now", "loud", "s","time", "see", "ve", "much", "got",
"go", "way", "tongue" ,"still", "really", "very","d","make", "man", "e", "going",
"back", "thing" , "us", "also", "t", "someone", "say", "something", "day", "look",
"first", "year", "work","looks", "makes", "years", "take", "made", "said",
"life", "post", "things", "find", "getting"
)
# 保留的情感功能词
keep_words <- c("not", "no", "never")
final_stopwords <- setdiff(custom_stopwords, keep_words)
# 分词并移除停用词
tokens <- text2vec::word_tokenizer(tolower(preprocessed_text))
tokens_filtered <- lapply(tokens, function(x) {
x[!x %in% final_stopwords]
})
# 创建itoken迭代器
it <- text2vec::itoken(tokens_filtered, progressbar = FALSE)
# 创建并修剪词汇表（1-3 gram）
vocab <- text2vec::create_vocabulary(it, ngram = c(1L, 3L)) %>%
text2vec::prune_vocabulary(
term_count_min = min_df,
doc_proportion_max = max_df,
vocab_term_max = max_features
)
# 创建向量器和TF-IDF模型
vectorizer <- text2vec::vocab_vectorizer(vocab)
tfidf <- text2vec::TfIdf$new()
# 创建TF-IDF稀疏矩阵
dtm <- text2vec::create_dtm(it, vectorizer)
tfidf_matrix <- tfidf$fit_transform(dtm)
# 返回结果
return(list(
tfidf_model = tfidf,
vectorizer = vectorizer,
tfidf_matrix = tfidf_matrix
))
}
# 示例文本（正面、负面、中性、俚语等）
sample_texts <- readLines(system.file("extdata", "go_emotions_train_text_processed.csv", package = "text2emotion"), warn = FALSE)
trained <- train_tfidf_model(sample_texts)
devtools::test()
rm(list = c("preprocess_text", "train_tfidf_model"))
devtools::test()
devtools::test()
devtools::test()
devtools::document()
install.packages(c("caret", "Matrix"))
devtools::document()
devtools::load_all()
install.packages("prodlim")
> devtools::load_all()
devtools::load_all()
devtools::document()
devtools::test()
devtools::test()
devtools::test()
devtools::test()
devtools::test()
usethis::use_vignette("text2emotion")
devtools::test()
devtools::test()
devtools::test()
devtools::test()
devtools::test()
devtools::test()
devtools::check()
install.packages("sass")
devtools::document()
devtools::check()
pkgbuild::has_build_tools(debug = TRUE)
devtools::check()
devtools::check()
devtools::document()
usethis::use_mit_license("Yusong Zhao,Fangyi Wang and Zisheng Qu")
devtools::document()
devtools::document()
devtools::document()
devtools::check()
file.exists("LICENSE")
readLines(".Rbuildignore")
desc <- readLines("DESCRIPTION")
desc[grepl("^License:", desc)]
devtools::document()
devtools::document()
devtools::check()
devtools::document()
devtools::check()
devtools::document()
devtools::document()
devtools::check()
file.exists("LICENSE")
libaray(magrittr)
library(magrittr)
#' Preprocess Text with Slang Handling
#'
#' This function performs multi-stage text preprocessing, including lowercasing,
#' HTML cleaning, punctuation normalization, contraction expansion, internet slang replacement,
#' emoticon replacement, and final standardization.
#'
#' @param text A character vector of input texts.
#' @param use_textclean Logical. Whether to use \code{textclean} for internet slang and emoticon replacement. Default is \code{TRUE}.
#' @param custom_slang A named character vector providing user-defined slang mappings. Optional.
#'
#' @return  A character vector of cleaned and normalized text.
#'
#' @details
#' The preprocessing pipeline includes:
#' \itemize{
#'   \item Lowercasing the text.
#'   \item Replacing HTML entities and non-ASCII characters.
#'   \item Expanding common English contractions (e.g., "I'm" -> "I am").
#'   \item Replacing internet slang and emoticons if \code{use_textclean} is \code{TRUE}.
#'   \item Handling additional slang defined by the user.
#'   \item Normalizing repeated punctuations and whitespace.
#' }
#'
#' @examples
#' preprocess_text("I'm feeling lit rn!!!")
#' preprocess_text("I can't believe it... lol :)", use_textclean = TRUE)
#'
#' @importFrom stringr str_to_lower str_replace_all str_squish
#' @importFrom textclean replace_html replace_non_ascii replace_internet_slang replace_emoticon
#' @importFrom magrittr %>%
#' @export
preprocess_text <- function(text,
use_textclean = TRUE,
custom_slang = NULL) {
# Stage 1: Basic cleaning
text <- text %>%
stringr::str_to_lower() %>%
# Replace HTML entities (e.g., &nbsp;)
textclean::replace_html() %>%
# Standardize punctuation (e.g., full-width to half-width)
textclean::replace_non_ascii()
# Stage 2: Contraction expansion
contractions <- c(
# Prioritize "ll" forms first
"i'll" = "i will",
"he'll" = "he will",
"she'll" = "she will",
"we'll" = "we will",
"you'll" = "you will",
"they'll" = "they will",
# Then expand other contractions
"i'm" = "i am",
"you're" = "you are",
"he's" = "he is",
"she's" = "she is",
"it's" = "it is",
"we're" = "we are",
"they're" = "they are",
"that's" = "that is",
"there's" = "there is",
"here's" = "here is",
"let's" = "let us",
# Finally, handle negations
"can't" = "can not",
"won't" = "will not",
"don't" = "do not",
"doesn't" = "does not",
"didn't" = "did not",
"isn't" = "is not",
"aren't" = "are not",
"wasn't" = "was not",
"weren't" = "were not",
"haven't" = "have not",
"hasn't" = "has not",
"hadn't" = "had not",
"shan't" = "shall not"
)
text <- text %>%
stringr::str_replace_all(contractions)
# Stage 3: Slang handling
if (use_textclean) {
text <- text %>%
textclean::replace_internet_slang() %>%
textclean::replace_emoticon()
}
# Define common slang terms
all_slang <- c(
"lit" = "extremely amazing",
"af" = "as fuck",
"u" = "you",
"ur" = "your",
"rn" = "right now",
"gg" = "good game",
"gl" = "good luck",
"hf" = "have fun",
"tbh" = "to be honest",
"idc" = "i don't care",
"op" = "overpowered",
"nerf" = "weaken",
"buff" = "strengthen",
"4" = "for",
"2" = "to",
"2nite" = "tonight",
"@" = "at",
"abt" = "about",
"f" = "fuck",
custom_slang
)
# Replace slang terms with their full forms
for (i in seq_along(all_slang)) {
text <- stringr::str_replace_all(
text,
stringr::regex(
paste0("\\b", names(all_slang)[i], "\\b"),
ignore_case = TRUE
),
all_slang[i]
)
}
if (!is.null(custom_slang)) {
for (i in seq_along(custom_slang)) {
text <- stringr::str_replace_all(
text,
stringr::regex(
paste0("\\b", names(custom_slang)[i], "\\b"),
ignore_case = TRUE
),
custom_slang[[i]]
)
}
}
# Stage 4: Final standardization
text %>%
# Normalize repeated punctuation (preserve emotional intensity)
stringr::str_replace_all("([!?.]){2,}", " \\1") %>%
# Standardize punctuation spacing
stringr::str_replace_all("([[:punct:]])", " \\1 ") %>%
stringr::str_squish()
}
